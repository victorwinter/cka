# **Cluster Architeture, Installation & Configuration**

Para a prática do cenário de Cluster Architecture, Installation & Configuration da certificação Certified Kubernetes Administrator (CKA), este repositório utilizará duas máquinas virtuais (VMs) provisionadas na AWS (Amazon Web Services), com a configuração t2.medium. 
Esse ambiente simula um cenário de cluster Kubernetes com dois nós, um provisionado para configurações e elementos do control-plane e outro relacionado ao worker node
Será utilizado o kubeadm para configurar e gerenciar o cluster Kubernetes. Isso é feito porque o kubeadm é uma das ferramentas e abordagens oficialmente cobradas no exame CKA.

Esse cenário é parte do exame CKA descrito no curriculum definido pela Cloud Native Compunting Foundation (CNCF)
[https://github.com/cncf/curriculum/blob/master/CKA_Curriculum_v1.31.pdf]

## **Detalhes da configuração:**
- Plataforma: AWS (Amazon Web Services).
- Tipo de Instância: 2 máquinas virtuais com o tipo de instância t2.medium 2vCpu e 4Gb de Memória.
- Sistema operacional: Ubuntu Server 22.04 LTS 64 Bit.
- Uso: Uma máquina virtual será configurada como Master Node, e a outra como Worker Node.
- Crie um novo Security Group (SG) para as instâncias do Kubernetes, garantindo que ele permita o acesso SSH (porta 22) de sua máquina local (ou de um intervalo de IPs seguro).
- Storage 30GiB
- Crie uma chave SSH para posterior conexão utilizando sua máquina local com um terminal de sua preferência
- Durante a criação das máquinas EC2, copie o id gerado pelo security group e acesse a seção de Edit Inbound Rules
- Clique em Add Rule, em type selecione 'All traffic' e em source selecione o id do próprio security group que havia copiado.
Obs.: Ressalta-se que essa não é a melhor opção, porém para exemplificação do cenário da prova essa liberação será necessária, essa liberação não deve ser utilizada em um ambiente de produção.
- Renomeie as máquinas de forma que uma seja seu control-plane e outra o worker-node, nesse cenário as máquinas terão os nomes cka-control-plane e cka-node
  
### **Configuração node Control Plane**
  
**Conectando nas máquinas EC2:**
- Após realizar o download da chave (.pem) gerada pela console aws 
- Copie a chave para um diretório de sua preferência
- Conceda a permissao chmod 400 para a chave que está no diretório.
- Realize uma conexão ssh na máquina definida como control-plane
  `ssh ubuntu@ip-do-host -i chave.pem`

Para esse primeiro cenário, iremos seguir a documentação oficial do Kubernetes adicionando a versão v1.31 para posteriormente executarmos a atualização.
[https://v1-31.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/]

Conectado na máquina EC2 control plane, execute os comandos abaixos conforme descrito na documentação oficial para instalação dos componentes:

1. 
- `sudo apt-get update`
- `sudo apt-get install -y apt-transport-https ca-certificates curl gpg`
    
2. 
- `curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.31/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg`

3. 
- `echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list`

4. 
- `sudo apt-get update`
- `sudo apt-get install -y kubelet kubeadm kubectl`
- `sudo apt-mark hold kubelet kubeadm kubectl` #comando utilizado para marcar os componentes kubeadm,kubelet e kubectl de modo que eles não sofram atualizações.

5.
- `sudo systemctl enable --now kubelet`

**Containerd:**
Para a configuração do Kubernetes neste cenário, o containerd será utilizado como o runtime de contêineres. 
O containerd é uma parte essencial do ecossistema Kubernetes, responsável pela execução e gerenciamento de contêineres.
Embora o containerd seja um componente fundamental para o funcionamento do Kubernetes, é importante ressaltar que a configuração do containerd não será cobrada no exame CKA, pois ele já virá pré-configurado em muitas distribuições e ambientes Kubernetes.
O objetivo de demonstrar a configuração além de melhor entendimento e aprofundamento no cenário é mostrar como é executada.
Abaixo a sequência de comandos que deverão ser utilizados:

1 - Ativar dois módulos de kernel: Overlay e br_netfilter

`cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF`

2. Carregue os dois módulos
- `sudo modprobe overlay`
- `sudo modprobe br_netfilter`

3. Habilitando algumas flags, ex: ipforward, netbridge
Crie um arquivo no caminho:

`/etc/sysctl.d/kubernetes.conf`

Edite o arquivo e insira o conteúdo:

`net.ipv4.ip_forward = 1
net.ipv4.conf.all.forwarding = 1
net.ipv6.conf.all.forwarding = 1
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.conf.all.rp_filter = 0
net.ipv6.conf.all.rp_filter = 0`

5. Após inserir o conteúdo e salvar o arquivo, execute o comando para carregar os módulos/flags:
- `sudo sysctl --system`

5. Instalação containerd
- `apt install -y containerd`
- `mkdir -p /etc/containerd`

6. Gere o arquivo de configuração padrão do containerd e redirecione a saída para um arquivo config.toml
- `containerd config default>/etc/containerd/config.toml`

7. Altere o valor do conteúdo config.toml modificando o valor SystemdCgroup para true, para isso, pode-se utilizar o comando abaixo para substituir todos os valores:
- `sed -i 's/SystemdCgroup.*/SystemdCgroup = true/g' /etc/containerd/config.toml`

8. Inicie o containerd
- `systemctl enable containerd`
- `systemctl start containerd`
- `systemctl status containerd`

Pré-requisitos instalados.

**Kubeadm Init:**
[https://v1-31.docs.kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/]

1. Após executar todos os passos anteriores e certificar de que os serviços estão instalados e em execução conforme esperado.
Iremos inicializar o master node de um cluster Kubernetes, configurando o plano de controle, criando os certificados necessários e gerando o comando para adicionar nós de trabalho (worker nodes) ao cluster, utilize o comando:
- `kubeadm init`

2. Finalizando a criação do cluster com o comando kubeadm init, execute os comandos solicitados na finalização do processo para a conclusão:
- `mkdir -p $HOME/.kube`
- `sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config`
- `sudo chown $(id -u):$(id -g) $HOME/.kube/config`

**Container Network Interface (CNI)**

A instalação da CNI em si, não é cobrada na prova de ceritificação, se houver algo relacionado, todos os comandos necessários e os steps serão informados durante a prova.
Para que nosso node criado nos passos anteriores fique com status de Ready, será necessário realizar a configuração da CNI

Iremos utilizar a documentação da Cilium [https://docs.cilium.io/en/v1.14/installation/k8s-install-kubeadm/#installation-using-kubeadm]

1. Copie e execute o comando para baixar e instalar o binário da Cilium:
`CILIUM_CLI_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/cilium-cli/main/stable.txt)
CLI_ARCH=amd64
if [ "$(uname -m)" = "aarch64" ]; then CLI_ARCH=arm64; fi
curl -L --fail --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${CILIUM_CLI_VERSION}/cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}
sha256sum --check cilium-linux-${CLI_ARCH}.tar.gz.sha256sum
sudo tar xzvfC cilium-linux-${CLI_ARCH}.tar.gz /usr/local/bin
rm cilium-linux-${CLI_ARCH}.tar.gz{,.sha256sum}`

2. Execute a instalação
- `cilium install`

3. Verifique o status da instalação
- `cilium status`

4. Verifique se o node está disponível (Ready)
- `kubectl get node`
